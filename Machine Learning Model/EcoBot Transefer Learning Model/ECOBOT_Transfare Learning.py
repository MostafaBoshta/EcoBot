# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d-2vII4pULMJc0rEXbP5qccAFVQ2lNk1
"""

#Marine debris training  on Nasa noaa  & unsplash & other randome free images
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
from sklearn.metrics import classification_report
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
from tqdm import tqdm_notebook
import numpy as np
from tensorflow.keras import preprocessing
from keras.layers import Input, Conv2DTranspose
from tensorflow.keras import utils
import matplotlib.pyplot as plot
import tensorflow as tf
import numpy as np
import pandas as pd
import PIL as image
import PIL
import datetime
import zipfile
import pathlib
import time
import os

ECOBOT_validation_dir = pathlib.Path('/content/drive/MyDrive/Colab Notebooks/ECOBOT dataset/validation')
ECOBOT_train_dir = pathlib.Path('/content/drive/MyDrive/Colab Notebooks/ECOBOT dataset/Training')
image_count = len(list(ECOBOT_train_dir.glob('*/*.jpg')))
print(image_count)

#loading images
batch_size = 32
img_h = 256
img_w = 256
train_ds = tf.keras.preprocessing.image_dataset_from_directory(ECOBOT_train_dir,validation_split=0.2
                                                              ,subset="training",seed=123,
                                                             batch_size = batch_size, image_size=(img_h,img_w))

batch_size = 32
img_h =256
img_w = 256
validation_ds = tf.keras.preprocessing.image_dataset_from_directory(ECOBOT_validation_dir,validation_split=0.2
                                                              ,subset="validation",seed=123,
                                                             batch_size = batch_size, image_size=(img_h,img_w))

class_names = train_ds.class_names
print(class_names)

plot.figure(figsize=(10, 10))
for images, labels in train_ds.take(10):
    for i in range(9):
        ax = plot.subplot(3, 3, i + 1)
        plot.imshow(images[i].numpy().astype("uint8"))
        plot.title(class_names[labels[i]])
        plot.axis("off")

#using Xception model for better accuracy
ECOBOT_Base_model =Image_shape = (128,128,3)
ECOBOT_Base_model = tf.keras.applications.MobileNetV2(input_shape=Image_shape, include_top=False, weights="imagenet")
ECOBOT_Base_model.summary()

ECOBOT_Base_model.trainable = False
ECOBOT_Base_model.output

global_average_layer = tf.keras.layers.GlobalAveragePooling2D()(ECOBOT_Base_model.output)

#prediction layer / output layer

Output_layer = tf.keras.layers.Dense(units=1, activation='sigmoid')(global_average_layer)

#our model
ECOBOT_model = tf.keras.models.Model(inputs=ECOBOT_Base_model.input, outputs= Output_layer)
ECOBOT_model.summary()

#compilation
ECOBOT_model.compile(optimizer= tf.keras.optimizers.RMSprop(learning_rate = 0.0001),loss = "categorical_crossentropy"
              ,metrics=["accuracy"])
data_gen_train = ImageDataGenerator(rescale=1/255.)
data_gen_valid = ImageDataGenerator(rescale=1/255.)

#training the our model
train_generator = data_gen_train.flow_from_directory(ECOBOT_train_dir,
                                                     target_size=(128,128), batch_size=128,
                                                     class_mode="categorical")
valid_generator = data_gen_valid.flow_from_directory(ECOBOT_validation_dir,
                                                     target_size=(128,128), 
                                                     batch_size=128, class_mode="categorical")
ECOBOT_model.fit(train_generator, epochs=5, validation_data=valid_generator)

#Final evaluation
valid_loss, valid_accuracy = ECOBOT_model.evaluate(valid_generator)
print("Validation accuracy after fine tuning: {}".format(valid_accuracy))

